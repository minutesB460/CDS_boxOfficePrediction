{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental arrows\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental symbols & pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Symbols & pictographs extended-A\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols & pictographs extended-B\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\" \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Remove stopwords，punctuations，html tags，emojis and transform into lowercase\n",
    "def preprocess_text(text):\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace(\",\", \" , \").replace(\".\", \" . \").replace(\"-\", \" - \").replace(\"/\", \" / \")\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    words = text.split()\n",
    "    filtered_sentence = \" \".join(word.translate(table) for word in words if word not in stop_words)\n",
    "    return filtered_sentence.strip()\n",
    "\n",
    "def scrape_imdb_reviews(movie_id):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    url = f\"https://www.imdb.com/title/{movie_id}/reviews\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Click the btn to load more reviews\n",
    "    while True:\n",
    "        try:\n",
    "            load_more_button = driver.find_element(By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n",
    "            load_more_button.click()\n",
    "            wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, \".ipl-load-more__load-indicator\")))\n",
    "            time.sleep(2)  \n",
    "        except Exception:\n",
    "            break  \n",
    "\n",
    "    # Get the full HTML \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()  \n",
    "\n",
    "    #Extract movie name\n",
    "    movie_name = soup.select_one(\"[data-testid='subtitle']\")\n",
    "\n",
    "    # Extract review data\n",
    "    title_reviews = []\n",
    "    content_reviews = []\n",
    "    review_date = []\n",
    "\n",
    "    for review_block in soup.select(\"article.user-review-item\"):\n",
    "        try:\n",
    "            title = review_block.select_one(\"h3.ipc-title__text\").text.strip()\n",
    "            content = review_block.select_one(\"div.ipc-html-content-inner-div\").text.strip()\n",
    "            date = review_block.select_one(\"li.review-date\").text.strip()\n",
    "            title_reviews.append(title)\n",
    "            content_reviews.append(content)\n",
    "            review_date.append(date)\n",
    "        except AttributeError:\n",
    "            print(\"Skipping a re view that cannot be parsed\")\n",
    "\n",
    "    # check the number of extracted reviews\n",
    "    print(f\"number of review titles: {len(title_reviews)}\")\n",
    "    print(f\"number of review content: {len(content_reviews)}\")\n",
    "    print(f\"number of review date: {len(review_date)}\")\n",
    "\n",
    "    processed_titles = [preprocess_text(title) for title in title_reviews]\n",
    "    processed_reviews = [preprocess_text(review) for review in content_reviews]\n",
    "\n",
    "    reviews_df = pd.DataFrame({\n",
    "        \"Movie Name\": movie_name,\n",
    "        \"Review Title\": processed_titles,\n",
    "        \"Review Content\": processed_reviews,\n",
    "        \"Review Date\": review_date\n",
    "    })\n",
    "\n",
    "    csv_filename = f\"{movie_id}_Cleaned_Reviews.csv\"\n",
    "    reviews_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(reviews_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "number of review titles: 21\n",
      "number of review content: 21\n",
      "number of review date: 21\n",
      "                  Movie Name                Review Title  \\\n",
      "0  Spider-Man: Far from Home            teen movie twist   \n",
      "1  Spider-Man: Far from Home  one best spider  man movie   \n",
      "2  Spider-Man: Far from Home                     amazing   \n",
      "3  Spider-Man: Far from Home            effort execution   \n",
      "4  Spider-Man: Far from Home                      adored   \n",
      "\n",
      "                                      Review Content   Review Date  \n",
      "0  movie breath fresh air  fun romp europe favour...   Sep 7, 2019  \n",
      "1  amazing movie  many surprises movie  3d effect...  Jul 15, 2019  \n",
      "2  movie much better 1st installment  cgi good gy...  Sep 11, 2019  \n",
      "3  movie hands best mcu movie yet  beginning end ...   Jul 3, 2019  \n",
      "4  like folks absoultley adored movie ton action ...  Jul 13, 2019  \n"
     ]
    }
   ],
   "source": [
    "# Access the IMDB review page\n",
    "movie_id = \"tt6320628\" \n",
    "scrape_imdb_reviews(movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Function to get IMDb Top 250 Movie IDs\n",
    "def get_imdb_top_250():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in the background\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    url = \"https://www.imdb.com/chart/top/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    movies = []\n",
    "    # for movie in soup.select(\"div.sc-ee514ad1-0.kYZRWL.cli-poster-container\"):\n",
    "    #     movie_title = movie.select_one(\"h3.ipc-title__text\")\n",
    "    #     movie_id = movie[\"href\"].split(\"/\")[2]  # Extracts the movie ID (e.g., tt0111161)\n",
    "    #     movies.append({\"movie_id\": movie_id, \"title\": movie_title})\n",
    "\n",
    "    for movie in soup.select(\"h3.ipc-title__text\"):  \n",
    "        movie_title = movie.text.strip()\n",
    "        movies.append({\"Movie Title\": movie_title})\n",
    "\n",
    "    return movies[:5]  # Return top 5 movies (change this if needed)\n",
    "\n",
    "get_imdb_top_250()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "res = requests.get(\"https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm.I\")\n",
    "#print(res)\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "for card in soup.select('li.ipc-metadata-list-summary-item'):\n",
    "    data.append({\n",
    "        \"title\": card.select_one('h3.ipc-title__text').text.strip()\n",
    "        # \"year\": card.select_one('.titleColumn span').text,\n",
    "        # 'rating': card.select_one('td[class=\"ratingColumn imdbRating\"]').get_text(strip=True)\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "#df.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Idiots : 1187043\n",
      "3 Idiots : 3685624\n",
      "3 Idiots : 28238283\n",
      "3 Idiots w/GUNS : 0222441\n",
      "3 Idiots and a Wise Man : 21612358\n",
      "Three Idiots to a Team : 29720863\n",
      "Mugguru Monagallu : 15121916\n",
      "3 Idiots on Wheels : 6689378\n",
      "Scotch Mist - A Tale of Three English Idiots in Search of Britain's Northernmost Monsters : 31444403\n",
      "Kidnap in Rome : 1575673\n",
      "3 Idiots : 12049418\n",
      "3 Idiots : 33501685\n",
      "3 Idiot Heroes : 30247415\n",
      "Three Idiots : 34207697\n",
      "Three Idiots : 16345748\n",
      "The Idiots : 0154421\n",
      "3 Idiots Try Candy! : 8474256\n",
      "God and 3 Idiots : 25393152\n",
      "Confessions of Three Idiots : 21124554\n",
      "Idiots Are People Three! : 2179303\n"
     ]
    }
   ],
   "source": [
    "# importing the module \n",
    "import imdb \n",
    "   \n",
    "# creating instance of IMDb \n",
    "ia = imdb.IMDb() \n",
    "   \n",
    "# name  \n",
    "name = \"3 idiots\"\n",
    "   \n",
    "# searching the name  \n",
    "search = ia.search_movie(name) \n",
    "  \n",
    "  \n",
    "# loop for printing the name and id \n",
    "for i in range(len(search)): \n",
    "      \n",
    "    # getting the id \n",
    "    id = search[i].movieID \n",
    "      \n",
    "    # printing it \n",
    "    print(search[i]['title'] + \" : \" + id ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Movie Name                Review Title  \\\n",
      "0  Spider-Man: Far from Home            teen movie twist   \n",
      "1  Spider-Man: Far from Home  one best spider  man movie   \n",
      "2  Spider-Man: Far from Home                     amazing   \n",
      "3  Spider-Man: Far from Home            effort execution   \n",
      "4  Spider-Man: Far from Home                      adored   \n",
      "\n",
      "                                      Review Content   Review Date  \n",
      "0  movie breath fresh air  fun romp europe favour...   Sep 7, 2019  \n",
      "1  amazing movie  many surprises movie  3d effect...  Jul 15, 2019  \n",
      "2  movie much better 1st installment  cgi good gy...  Sep 11, 2019  \n",
      "3  movie hands best mcu movie yet  beginning end ...   Jul 3, 2019  \n",
      "4  like folks absoultley adored movie ton action ...  Jul 13, 2019  \n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental arrows\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental symbols & pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Symbols & pictographs extended-A\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols & pictographs extended-B\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\" \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Remove stopwords，punctuations，html tags，emojis and transform into lowercase\n",
    "def preprocess_text(text):\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace(\",\", \" , \").replace(\".\", \" . \").replace(\"-\", \" - \").replace(\"/\", \" / \")\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    words = text.split()\n",
    "    filtered_sentence = \" \".join(word.translate(table) for word in words if word not in stop_words)\n",
    "    return filtered_sentence.strip()\n",
    "\n",
    "processed_titles = [preprocess_text(title) for title in title_reviews]\n",
    "processed_reviews = [preprocess_text(review) for review in content_reviews]\n",
    "\n",
    "reviews_df = pd.DataFrame({\n",
    "    \"Movie Name\": movie_name,\n",
    "    \"Review Title\": processed_titles,\n",
    "    \"Review Content\": processed_reviews,\n",
    "    \"Review Date\": review_date\n",
    "})\n",
    "\n",
    "csv_filename = f\"{movie_id}_Cleaned_Reviews.csv\"\n",
    "reviews_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(reviews_df.head())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
