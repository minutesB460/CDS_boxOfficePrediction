{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import imdb\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental arrows\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental symbols & pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Symbols & pictographs extended-A\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols & pictographs extended-B\n",
    "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                           u\"\\U000024C2-\\U0001F251\" \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Remove stopwords，punctuations，html tags，emojis and transform into lowercase\n",
    "def preprocess_text(text):\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace(\",\", \" , \").replace(\".\", \" . \").replace(\"-\", \" - \").replace(\"/\", \" / \")\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    words = text.split()\n",
    "    filtered_sentence = \" \".join(word.translate(table) for word in words if word not in stop_words)\n",
    "    return filtered_sentence.strip()\n",
    "\n",
    "def scrape_imdb_reviews(movie_ids):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # Manually set local chromedriver path\n",
    "    # CHROMEDRIVER_PATH = \"/opt/homebrew/bin/chromedriver\"\n",
    "    # service = Service(CHROMEDRIVER_PATH)\n",
    "    # driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    all_reviews = []\n",
    "\n",
    "    for movie_id in movie_ids:\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{movie_id}/reviews\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        load_more_clicked = 0\n",
    "        # Click the btn to load more reviews\n",
    "        while load_more_clicked < 5:\n",
    "            try:\n",
    "                load_more_button = driver.find_element(By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n",
    "                # load_more_button.click()\n",
    "                load_more_button.send_keys('\\n')\n",
    "                wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, \".ipl-load-more__load-indicator\")))\n",
    "                time.sleep(2)\n",
    "                load_more_clicked +=1\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                break\n",
    "        print(load_more_clicked)\n",
    "\n",
    "        # Get the full HTML \n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\") \n",
    "\n",
    "        #Extract movie name\n",
    "        movie_name_tag = soup.select_one(\"[data-testid='subtitle']\")\n",
    "        movie_name = movie_name_tag.text.strip() if movie_name_tag else f\"Unknown ({movie_id})\"\n",
    "\n",
    "        # Extract review data\n",
    "        title_reviews = []\n",
    "        content_reviews = []\n",
    "        review_date = []\n",
    "\n",
    "        for review_block in soup.select(\"article.user-review-item\"):\n",
    "            try:\n",
    "                title = review_block.select_one(\"h3.ipc-title__text\").text.strip()\n",
    "                content = review_block.select_one(\"div.ipc-html-content-inner-div\").text.strip()\n",
    "                date = review_block.select_one(\"li.review-date\").text.strip()\n",
    "                title_reviews.append(title)\n",
    "                content_reviews.append(content)\n",
    "                review_date.append(date)\n",
    "            except AttributeError:\n",
    "                print(\"Skipping a review that cannot be parsed\")\n",
    "\n",
    "        # Check the number of extracted reviews\n",
    "        print(f\"number of review titles: {len(title_reviews)}\")\n",
    "        print(f\"number of review content: {len(content_reviews)}\")\n",
    "        print(f\"number of review date: {len(review_date)}\")\n",
    "\n",
    "        processed_titles = [preprocess_text(title) for title in title_reviews]\n",
    "        processed_reviews = [preprocess_text(review) for review in content_reviews]\n",
    "\n",
    "        for title, content, date in zip(processed_titles, processed_reviews, review_date):\n",
    "            all_reviews.append({\"Movie Name\": movie_name, \"Review Title\": title, \"Review Content\": content, \"Review Date\": date})\n",
    "\n",
    "    driver.quit() \n",
    "\n",
    "    reviews_df = pd.DataFrame(all_reviews)\n",
    "    csv_filename = \"data/IMDb_Cleaned_Reviews.csv\"\n",
    "    reviews_df.to_csv(csv_filename, index=False)\n",
    "    print(reviews_df.head()) \n",
    "\n",
    "# movie_ids = [\"tt1375666\",\"tt6320628\"]  \n",
    "# scrape_imdb_reviews(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_ids(movie_names):\n",
    "    ia = imdb.IMDb()\n",
    "    movie_ids = []\n",
    "\n",
    "    for name in movie_names:\n",
    "        search = ia.search_movie(name)\n",
    "        if search:\n",
    "            movie_id = f\"tt{search[0].movieID}\" \n",
    "            movie_ids.append(movie_id)  # Store as a string\n",
    "        else:\n",
    "            print(f\"No IMDb ID found for: {name}\")\n",
    "\n",
    "    return movie_ids\n",
    "\n",
    "# movie_names = [\"Inception\", \"The Dark Knight\", \"Forrest Gump\", \"The Matrix\", \"Interstellar\"]\n",
    "# movie_ids = get_imdb_ids(movie_names)\n",
    "# print(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_movie_list_names(url):\n",
    "    movie_names = []\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # Manually set local chromedriver path\n",
    "    # CHROMEDRIVER_PATH = \"/opt/homebrew/bin/chromedriver\" \n",
    "    # service = Service(CHROMEDRIVER_PATH)\n",
    "    # driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3) \n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()  \n",
    "\n",
    "    # Extract movie titles\n",
    "    for card in soup.select('div.sc-f30335b4-0'):\n",
    "        try:\n",
    "            title = card.select_one('h3.ipc-title__text').text.strip()\n",
    "            movie_names.append(title)\n",
    "        except AttributeError:\n",
    "            print(\"Skipping a movie that cannot be parsed.\")\n",
    "\n",
    "    return movie_names \n",
    "\n",
    "# url = \"https://www.imdb.com/chart/moviemeter/\"\n",
    "# movie_names = get_imdb_movie_list_names(url)\n",
    "# print(movie_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anora', 'The Brutalist']\n",
      "['tt28607951', 'tt8999762']\n",
      "5\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "number of review titles: 105\n",
      "number of review content: 105\n",
      "number of review date: 105\n",
      "5\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "Skipping a re view that cannot be parsed\n",
      "number of review titles: 119\n",
      "number of review content: 119\n",
      "number of review date: 119\n",
      "  Movie Name                             Review Title  \\\n",
      "0      Anora            pretty woman meets uncut gems   \n",
      "1      Anora                         cinderella lives   \n",
      "2      Anora                         expect like much   \n",
      "3      Anora  chaotic  heartbreaking glimpse survival   \n",
      "4      Anora                       get hype around it   \n",
      "\n",
      "                                      Review Content   Review Date  \n",
      "0  anora early career magnum opus sean baker cont...   Nov 3, 2024  \n",
      "1  watched one best films year  athens festival n...   Oct 4, 2024  \n",
      "2  movie traumatized abused child grows perpetuat...  Dec 20, 2024  \n",
      "3  sean baker turns anora one movies seem glide e...  Jan 29, 2025  \n",
      "4  first 40 minutes quite misleading  likely catc...  Dec 19, 2024  \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.imdb.com/chart/moviemeter/\" #Most Popular Movies List\n",
    "movie_names = get_imdb_movie_list_names(url)\n",
    "\n",
    "# Extract only the first ten movie names for test\n",
    "first_ten_movies = movie_names[:10]\n",
    "print(first_ten_movies)\n",
    "movie_ids = get_imdb_ids(first_ten_movies)\n",
    "print(movie_ids)\n",
    "scrape_imdb_reviews(movie_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
